{"ast":null,"code":"var _s = $RefreshSig$();\nimport { useState, useEffect, useRef } from 'react';\nexport const useAudioLevel = stream => {\n  _s();\n  const [isSpeaking, setIsSpeaking] = useState(false);\n  const audioContextRef = useRef(null);\n  const analyserRef = useRef(null);\n  const animationRef = useRef(null);\n  useEffect(() => {\n    if (!stream) return;\n    try {\n      const audioContext = new (window.AudioContext || window.webkitAudioContext)();\n      const analyser = audioContext.createAnalyser();\n      const microphone = audioContext.createMediaStreamSource(stream);\n      analyser.fftSize = 512;\n      analyser.smoothingTimeConstant = 0.8;\n      microphone.connect(analyser);\n      audioContextRef.current = audioContext;\n      analyserRef.current = analyser;\n      const dataArray = new Uint8Array(analyser.frequencyBinCount);\n      const threshold = 30; // Adjust sensitivity\n\n      const detectAudio = () => {\n        analyser.getByteFrequencyData(dataArray);\n        const average = dataArray.reduce((a, b) => a + b) / dataArray.length;\n        setIsSpeaking(average > threshold);\n        animationRef.current = requestAnimationFrame(detectAudio);\n      };\n      detectAudio();\n      return () => {\n        if (animationRef.current) {\n          cancelAnimationFrame(animationRef.current);\n        }\n        if (audioContextRef.current) {\n          audioContextRef.current.close();\n        }\n      };\n    } catch (error) {\n      console.error('Error setting up audio detection:', error);\n    }\n  }, [stream]);\n  return isSpeaking;\n};\n_s(useAudioLevel, \"2nlIYZ/W78Q2TGQ0NBxJXWZ+0j8=\");","map":{"version":3,"names":["useState","useEffect","useRef","useAudioLevel","stream","_s","isSpeaking","setIsSpeaking","audioContextRef","analyserRef","animationRef","audioContext","window","AudioContext","webkitAudioContext","analyser","createAnalyser","microphone","createMediaStreamSource","fftSize","smoothingTimeConstant","connect","current","dataArray","Uint8Array","frequencyBinCount","threshold","detectAudio","getByteFrequencyData","average","reduce","a","b","length","requestAnimationFrame","cancelAnimationFrame","close","error","console"],"sources":["/home/cristian/Documentos/7mo/lenguajes_programacion/Videoconferencia-app/client/src/hooks/useAudioLevel.js"],"sourcesContent":["import { useState, useEffect, useRef } from 'react';\n\nexport const useAudioLevel = (stream) => {\n    const [isSpeaking, setIsSpeaking] = useState(false);\n    const audioContextRef = useRef(null);\n    const analyserRef = useRef(null);\n    const animationRef = useRef(null);\n\n    useEffect(() => {\n        if (!stream) return;\n\n        try {\n            const audioContext = new (window.AudioContext || window.webkitAudioContext)();\n            const analyser = audioContext.createAnalyser();\n            const microphone = audioContext.createMediaStreamSource(stream);\n\n            analyser.fftSize = 512;\n            analyser.smoothingTimeConstant = 0.8;\n            microphone.connect(analyser);\n\n            audioContextRef.current = audioContext;\n            analyserRef.current = analyser;\n\n            const dataArray = new Uint8Array(analyser.frequencyBinCount);\n            const threshold = 30; // Adjust sensitivity\n\n            const detectAudio = () => {\n                analyser.getByteFrequencyData(dataArray);\n                const average = dataArray.reduce((a, b) => a + b) / dataArray.length;\n\n                setIsSpeaking(average > threshold);\n                animationRef.current = requestAnimationFrame(detectAudio);\n            };\n\n            detectAudio();\n\n            return () => {\n                if (animationRef.current) {\n                    cancelAnimationFrame(animationRef.current);\n                }\n                if (audioContextRef.current) {\n                    audioContextRef.current.close();\n                }\n            };\n        } catch (error) {\n            console.error('Error setting up audio detection:', error);\n        }\n    }, [stream]);\n\n    return isSpeaking;\n};\n"],"mappings":";AAAA,SAASA,QAAQ,EAAEC,SAAS,EAAEC,MAAM,QAAQ,OAAO;AAEnD,OAAO,MAAMC,aAAa,GAAIC,MAAM,IAAK;EAAAC,EAAA;EACrC,MAAM,CAACC,UAAU,EAAEC,aAAa,CAAC,GAAGP,QAAQ,CAAC,KAAK,CAAC;EACnD,MAAMQ,eAAe,GAAGN,MAAM,CAAC,IAAI,CAAC;EACpC,MAAMO,WAAW,GAAGP,MAAM,CAAC,IAAI,CAAC;EAChC,MAAMQ,YAAY,GAAGR,MAAM,CAAC,IAAI,CAAC;EAEjCD,SAAS,CAAC,MAAM;IACZ,IAAI,CAACG,MAAM,EAAE;IAEb,IAAI;MACA,MAAMO,YAAY,GAAG,KAAKC,MAAM,CAACC,YAAY,IAAID,MAAM,CAACE,kBAAkB,EAAE,CAAC;MAC7E,MAAMC,QAAQ,GAAGJ,YAAY,CAACK,cAAc,CAAC,CAAC;MAC9C,MAAMC,UAAU,GAAGN,YAAY,CAACO,uBAAuB,CAACd,MAAM,CAAC;MAE/DW,QAAQ,CAACI,OAAO,GAAG,GAAG;MACtBJ,QAAQ,CAACK,qBAAqB,GAAG,GAAG;MACpCH,UAAU,CAACI,OAAO,CAACN,QAAQ,CAAC;MAE5BP,eAAe,CAACc,OAAO,GAAGX,YAAY;MACtCF,WAAW,CAACa,OAAO,GAAGP,QAAQ;MAE9B,MAAMQ,SAAS,GAAG,IAAIC,UAAU,CAACT,QAAQ,CAACU,iBAAiB,CAAC;MAC5D,MAAMC,SAAS,GAAG,EAAE,CAAC,CAAC;;MAEtB,MAAMC,WAAW,GAAGA,CAAA,KAAM;QACtBZ,QAAQ,CAACa,oBAAoB,CAACL,SAAS,CAAC;QACxC,MAAMM,OAAO,GAAGN,SAAS,CAACO,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,CAAC,GAAGT,SAAS,CAACU,MAAM;QAEpE1B,aAAa,CAACsB,OAAO,GAAGH,SAAS,CAAC;QAClChB,YAAY,CAACY,OAAO,GAAGY,qBAAqB,CAACP,WAAW,CAAC;MAC7D,CAAC;MAEDA,WAAW,CAAC,CAAC;MAEb,OAAO,MAAM;QACT,IAAIjB,YAAY,CAACY,OAAO,EAAE;UACtBa,oBAAoB,CAACzB,YAAY,CAACY,OAAO,CAAC;QAC9C;QACA,IAAId,eAAe,CAACc,OAAO,EAAE;UACzBd,eAAe,CAACc,OAAO,CAACc,KAAK,CAAC,CAAC;QACnC;MACJ,CAAC;IACL,CAAC,CAAC,OAAOC,KAAK,EAAE;MACZC,OAAO,CAACD,KAAK,CAAC,mCAAmC,EAAEA,KAAK,CAAC;IAC7D;EACJ,CAAC,EAAE,CAACjC,MAAM,CAAC,CAAC;EAEZ,OAAOE,UAAU;AACrB,CAAC;AAACD,EAAA,CAhDWF,aAAa","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}